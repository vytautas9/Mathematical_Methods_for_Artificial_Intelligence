---
title: "Mathematical Methods for Artificial Intelligence Lab 2"
author: "Vytautas Kraujalis"
date: '2021-10-03'
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


# Reading Data
```{r}
set.seed(123)

data <- read.csv("water_potability.csv")
```

# Required packages
```{r}
library(SmartEDA)
library(dplyr)
library(ggplot2)
library(mice)
library(VIM)
library(glmnet)
library(caret)
library(pROC)
```

# EDA, first look at the dataset
```{r}
ExpData(data,type=1)
```

We can see, that we have 10 numerical variables and 3276 observations, we can also notice, that 3 variables have missing variables.

```{r}
summary(data)
```

Variables "ph", "Sulfate" and "Trihalomethanes" have missing values. 


Let's look how our missing values are distributed:



```{r}
aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```

Out of `r nrow(data)` observations we have 61% of observations without any missing value. 19% of observations have only one missing variable. Variable "ph" contains almost 15% of missing values, while "Sulfate" has almost 24% of missing values, this may cause problems. "Trihalomethanes" has less than <5% of missing values.

We are going to use "mice" package for missing values imputation.
```{r}
imp <- mice(data)

summary(imp)
```

```{r}
data_noMissing <- complete(imp, 1)

xyplot(imp,Potability ~ ph+Sulfate+Trihalomethanes,pch=18,cex=1)

densityplot(imp)

```

The scatter plot of imputed data (red) and observed values (blue) shows that we did not produced any outliers. Density plots also shows no bad variation of imputed data.

# Pre-process
## Data split
```{r}
indices <- createDataPartition(data_noMissing$Potability, p = 0.8, list = FALSE)
train <- data_noMissing[indices,]
test <- data_noMissing[-indices,]

label_index <- which(colnames(train) == "Potability")
```

Splitted a dataset by 80% / 20% rule. Created a training dataset with `r nrow(train)` (`r nrow(train)/nrow(data)*100`%) observations and testing dataset with `r nrow(test)` (`r nrow(test)/nrow(data)*100`%) observations.


# Logistic Regression
```{r}
fit_glm_cv = cv.glmnet(as.matrix(train[, -label_index]), train[, label_index], family = "binomial", type.measure = "auc", keep = T, nfolds = 10)
plot(fit_glm_cv)
grid()
```

At first glance, our model on the training set does not perform well. Let's take the best result and run a logistic regression again

Using fitted logistic regression model on the testing dataset:
```{r}
fit_glm = glmnet(as.matrix(train[, -label_index]), train[, label_index], family = "binomial", lambda=fit_glm_cv$lambda.min)
test_glm <- predict(fit_glm, as.matrix(test[, -label_index]), type = "class")
confusionMatrix(as.factor(test_glm),as.factor(test$Potability),mode="everything")

temp <- confusionMatrix(as.factor(test_glm),as.factor(test$Potability),mode="everything")
```

The overall accuracy is 62%, but the No Information Rate is 0.63. We can see from the confusion table and from the NIR, that our model poorly predicts one class. 

Let's check the ROC curves:
```{r}
roc_glm <- roc.glmnet(fit_glm, newx = as.matrix(test[, -label_index]), newy=test$Potability)
ggplot(roc_glm, aes(x = FPR, y = TPR)) +
   geom_line() +
   geom_abline(slope = 1, color = "red", size = 1) +
   theme_minimal()

test_glm_response <- predict(fit_glm, as.matrix(test[, -label_index]),type="response")
auc(roc(test$Potability ~ test_glm_response))
```

The AUC is 0.53, so our model is as good as a random guess.

```{r}
formula <- as.formula(paste(' ~ .^2 + ',paste('poly(',colnames(train[, -label_index]),',2, raw=TRUE)[, 2]',collapse = ' + ')))

temp <- as.data.frame(model.matrix(formula, data=train[, -label_index]))
temp2 <- temp[, 2:ncol(temp)] %>% 
   bind_cols(Potability = train$Potability)
temp_label_index <- which(colnames(temp2) == "Potability")

temp_test <- as.data.frame(model.matrix(formula, data=test[, -label_index]))
temp2_test <- temp_test[, 2:ncol(temp_test)] %>% 
   bind_cols(Potability = test$Potability)

temp_fit_glm_cv = cv.glmnet(as.matrix(temp2[, -temp_label_index]), temp2[, temp_label_index], family = "binomial", type.measure = "auc", keep = T, nfolds = 10)
plot(temp_fit_glm_cv)
grid()




temp_fit_glm = glmnet(as.matrix(temp2[, -temp_label_index]), temp2[, temp_label_index], family = "binomial", lambda=temp_fit_glm_cv$lambda.min)
temp_test_glm <- predict(temp_fit_glm, as.matrix(temp2_test[, -temp_label_index]), type = "class")
confusionMatrix(as.factor(temp_test_glm),as.factor(test$Potability),mode="everything")

temp <- confusionMatrix(as.factor(test_glm),as.factor(test$Potability),mode="everything")

```

