---
title: "Mathematical Methods for Artificial Intelligence Lab 4"
author: "Vytautas Kraujalis"
date: '2021-11-20'
output: 
  pdf_document:
    toc: true 
    toc_depth: 3
    number_sections: true
    highlight: tango
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Gaussian Process
## Reading Data
```{r}
set.seed(123)

data_original <- read.csv("satellite_train.csv")
```

## Required packages
```{r}
library(SmartEDA)
library(dplyr)
library(ggplot2)
library(caret)

# Function for 6 class accuracy from confusion matrix
classAcc <- function(confusionMatrix) {
  class1 <- round(confusionMatrix$table[1, 1] / sum(confusionMatrix$table[, 1]) * 100, 1)
  class2 <- round(confusionMatrix$table[2, 2] / sum(confusionMatrix$table[, 2]) * 100, 1)
  class3 <- round(confusionMatrix$table[3, 3] / sum(confusionMatrix$table[, 3]) * 100, 1)
  class4 <- round(confusionMatrix$table[4, 4] / sum(confusionMatrix$table[, 4]) * 100, 1)
  class5 <- round(confusionMatrix$table[5, 5] / sum(confusionMatrix$table[, 5]) * 100, 1)
  class6 <- round(confusionMatrix$table[6, 6] / sum(confusionMatrix$table[, 6]) * 100, 1)
  acc <- c(class1, class2, class3, class4, class5, class6 )
  names(acc) <- colnames(confusionMatrix$table)
  return(acc)
}
```

## Parallel processing
```{r}
library(parallel) 
no_cores <- detectCores() - 1
library(doParallel)
cl <- makePSOCKcluster(no_cores)
registerDoParallel(cl)
```


## EDA, first look at the dataset
```{r}
ExpData(data_original,type=1)
```

We have a dataset of 4435 observations with 37 variables, all of the variables are numerical. All variables have no missing values. Let's change the response variable to factor type.

```{r}
data <- data_original %>% 
   mutate(V37 = as.factor(V37)) %>% 
   rename(Target = V37)
```

```{r}
data <- data %>% 
   mutate(
      Target = as.factor(case_when(
         Target == "1" ~ "Red Soil",
         Target == "2" ~ "Cotton Crop",
         Target == "3" ~ "Grey Soil",
         Target == "4" ~ "Damp Grey Soil",
         Target == "5" ~ "Soil With Vegetation Stubble",
         Target == "7" ~ "Very Damp Grey Soil",
         TRUE ~ "ERROR"
      ))
   )
```

Let's look at the target variable frequencies

```{r}
data %>% 
   group_by(Target) %>% 
   summarise(n = n()) %>% 
   mutate(n_prop = round(n / sum(n) * 100, 2))
```

Our target variable has 6 classes, the smallest class has 415 (9.4%) observations while the biggest class has 1072 (24.2%) observations.

Let's look at descriptive statistics of each variable:
```{r}
ExpNumStat(data,by ="A",round= 2, gp = "Target") %>% 
  select(Vname, min, max, mean, median, SD)
```

Nothing seems unordinary.

We should look at the correlation between variables
```{r}
# Correlation

corr_simple <- function(df,sig=0.5){
  corr <- cor(df)
  #prepare to drop duplicates and correlations of 1     
  corr[lower.tri(corr,diag=TRUE)] <- NA 
  #drop perfect correlations
  corr[corr == 1] <- NA 
  #turn into a 3-column table
  corr <- as.data.frame(as.table(corr))
  #remove the NA values from above 
  corr <- na.omit(corr) 
  #select significant values  
  corr <- subset(corr, abs(Freq) > sig) 
  #sort by highest correlation
  corr <- corr[order(-abs(corr$Freq)),] 
  return(corr)
}

correlation_matrix = cor(data %>% select(-Target))

length(findCorrelation(correlation_matrix, cutoff = 0.99))
length(findCorrelation(correlation_matrix, cutoff = 0.95))
length(findCorrelation(correlation_matrix, cutoff = 0.9))
```

We have `r length(findCorrelation(correlation_matrix, cutoff = 0.99))` variables with higher than .99 correlation.
We have `r length(findCorrelation(correlation_matrix, cutoff = 0.95))` variables with higher than .95 correlation.
We have `r length(findCorrelation(correlation_matrix, cutoff = 0.9))` variables with higher than .9 correlation.

We'll look through random scatter plots and see how our target variable is seperated across. We'll save some interesting combinations for later. P.S. we'll use jitter() function to overcome observation overlap.

```{r}
data_plot <- data %>% 
   select(sample(0:36, 1), sample(0:36, 1), Target)
data_plot_colnames <- colnames(data_plot)
colnames(data_plot) <- c("V_1", "V_2", "Target")
data_plot %>% 
   ggplot(aes(x = jitter(V_1), y = jitter(V_2), color = Target)) +
   geom_point() +
   xlab(data_plot_colnames[1]) +
   ylab(data_plot_colnames[2])

#combinations <- c("V2 - V3", "V30 - V11", "V7 - V3", "V3 - V24", "V31 - V32")
```

```{r}
data %>% 
   ggplot(aes(x = jitter(V2), y = jitter(V3), color = Target)) +
   geom_point() +
   theme_minimal()
```

Combination of V2 and V3 features shows quite significant separation of "Cotton Crop" group, while "Damp Grey Soil" has almost no separation. All other classes could be visually separated.

```{r}
data %>% 
   ggplot(aes(x = jitter(V11), y = jitter(V30), color = Target)) +
   geom_point() +
   theme_minimal()
```

once again, the "Cotton Crop" group seems separatable quite good, but now there's a mix of "Red Soil", "Grey Soil" and "Damp Grey Soil" all in one cluster, which could be hard to distinguish.

```{r}
data %>% 
   ggplot(aes(x = jitter(V3), y = jitter(V7), color = Target)) +
   geom_point() +
   theme_minimal()
```

Looking at the combination of V3 and V7 features, we see a clear linear combination, but the target variable is mixed all over the place.

```{r}
data %>% 
   ggplot(aes(x = jitter(V3), y = jitter(V24), color = Target)) +
   geom_point() +
   theme_minimal()
```

Using a combination of V3 and V24 features we can separate "Cotton Crop" easily, but the rest of the classes won't be separated so easily.

```{r}
data %>% 
   ggplot(aes(x = jitter(V31), y = jitter(V32), color = Target)) +
   geom_point() +
   theme_minimal()
```

Similar results as the plot before, but now the other classes could be separatable a bit better, only the "Damp Grey Soil" and "Soil With Vegetation Stubble" classes are not separatable that good.

It seems that our model could have a problem at detecting "Damp Grey Soil" class.

## Fitting models
Tried fitting Linear Gaussian Process and Gaussian Process with Polynomial Kernel but both methods took too long to compute...

### Gaussian Process - Variational Bayesian Multinomial Probit Regression
```{r}
fitControl <- trainControl(
  method = "cv",
  number = 2,
  classProbs = TRUE,
  savePredictions="all",
  verboseIter = TRUE)

gp.vbmp.fit <- train(Target ~ ., data = data %>% 
                   mutate(Target = factor(Target, labels = make.names(levels(Target)))), 
                 method = "vbmpRadial", 
                 trControl = fitControl,
                 preProcess=c("center", "scale","pca"))

```

```{r}
resamp_vbmp = gp.vbmp.fit$pred[gp.vbmp.fit$pred$estimateTheta == gp.vbmp.fit$bestTune[1,1],]
confusion_matrix <- confusionMatrix(resamp_vbmp$pred, resamp_vbmp$obs)

confusion_matrix

classAcc(confusion_matrix)
```

The overall accuracy of model is 89.7% which is much better than a random guess while NIR is 0.2417. The accuracies for each class shows what we predicted - the accuracy for "Damp Grey Soil" is only 60.2% while for other classes: 
+ "Cotton Crop" - 95.6%,
+ "Grey Soil" - 94.1%,
+ "Red Soil" - 97.5%,
+ "Soil With Vegetation Stubble" - 84.3%,
+ Very Damp Grey Soil" - 89.1%.

### Gaussian Process with Radial Basis Function Kernel
```{r}
fitControl <- trainControl(
  method = "cv",
  number = 2,
  classProbs = TRUE,
  savePredictions="all",
  verboseIter = TRUE)

gpGrid =  expand.grid(sigma = seq(0.01,0.2,0.01))


gp.fit <- train(Target ~ ., data = data %>% 
                   mutate(Target = factor(Target, labels = make.names(levels(Target)))), 
                 method = "gaussprRadial", 
                 trControl = fitControl,
                 preProcess=c("center", "scale","pca"),
                 tuneGrid = gpGrid)

```

Let's look which sigma gives the best accuracy:
```{r}
plot(gp.fit,metric = "Accuracy")
```

Best results are obtained when sigma is 0.15.

Using sigma = 0.15 let's look at the accuracies of each class and overall accuracy:
```{r}
resamp_rb = gp.fit$pred[gp.fit$pred$sigma == gp.fit$bestTune[1,1],]
confusion_matrix <- confusionMatrix(resamp_rb$pred, resamp_rb$obs)

confusion_matrix

classAcc(confusion_matrix)
```

The overall accuracy of model is 87.9% which is much better than a random guess while NIR is 0.2419. The accuracies for each class shows what we predicted - the accuracy for "Damp Grey Soil" is only 54.1% while for other classes: 
+ "Cotton Crop" - 97.9%,
+ "Grey Soil" - 92.9%,
+ "Red Soil" - 97.0%,
+ "Soil With Vegetation Stubble" - 72.3%,
+ Very Damp Grey Soil" - 89.6%.

### Support Vector Machines with Linear Kernel
```{r}
fitControl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  savePredictions="all",
  verboseIter = TRUE)

svmGrid =  expand.grid(C=seq(0.001,5,0.2))

svm.fit <- train(Target ~ ., data = data %>% 
                   mutate(Target = factor(Target, labels = make.names(levels(Target)))), 
                 method = "svmLinear", 
                 trControl = fitControl,
                 preProcess=c("center", "scale","pca"),
                 tuneGrid = svmGrid)
```

Let's look which Cost gives us the best accuracy:
```{r}
plot(svm.fit,metric = "Accuracy")
```

Best accuracy is obtained using Cost = 0.601.

Using Cost = 0.601 let's look at the accuracies:
```{r}
resamp_svm = svm.fit$pred[svm.fit$pred$C==svm.fit$bestTune[1,1],]

confusion_matrix <- confusionMatrix(resamp_svm$pred, resamp_svm$obs)

confusion_matrix

classAcc(confusion_matrix)
```

### Support Vector Machines with Radial Basis Function Kernel
```{r}
fitControl <- trainControl(
  method = "cv",
  number = 10,
  classProbs = TRUE,
  savePredictions="all",
  verboseIter = TRUE)

svmGrid =  expand.grid(C=seq(0.001,5,0.2), sigma = seq(0.01, 0.3, 0.09))

svm.radial.fit <- train(Target ~ ., data = data %>% 
                   mutate(Target = factor(Target, labels = make.names(levels(Target)))), 
                 method = "svmRadial", 
                 trControl = fitControl,
                 preProcess=c("center", "scale","pca"),
                 tuneGrid = svmGrid)
```

Let's look at the accuracy using different parameters:
```{r}
plot(svm.radial.fit,metric = "Accuracy")
```

Best accuracy is obtained using sigma = 0.1, Cost = 2.8, let's use those parameters to look at the class accuracies:
```{r}
resamp_svm_radial = svm.radial.fit$pred[svm.radial.fit$pred$C == svm.radial.fit$bestTune[1,2] & svm.radial.fit$pred$sigma == svm.radial.fit$bestTune[1,1],]

confusion_matrix <- confusionMatrix(resamp_svm_radial$pred, resamp_svm_radial$obs)

confusion_matrix

classAcc(confusion_matrix)
```

Overall accuracy is 74.4% while the accuracies for each class are:
+ Cotton Crop - 95.8%,
+ Damp Grey Soil - 46.3%,
+ Grey Soil - 96.5%,
+ Red Soil - 60.5%,
+ Soil With Vegetation Stubble - 32.3%,
+ Very Damp Grey Soil - 88.6%


## Comparison of models
```{r}
accuracies <- data.frame() %>% 
   bind_rows(
      classAcc(confusionMatrix(resamp_vbmp$pred, resamp_vbmp$obs)),
      classAcc(confusionMatrix(resamp_rb$pred, resamp_rb$obs)),
      classAcc(confusionMatrix(resamp_svm$pred, resamp_svm$obs)),
      classAcc(confusionMatrix(resamp_svm_radial$pred, resamp_svm_radial$obs))
             ) %>% 
   bind_cols(
      model = c("GP - Variational Bayesian Multinomial Probit Reg.", "GP - Radial Basis", "SVM - Linear Kernel", "SVM - Radial Kernel"),
      overall_accuracy = round(c(
         sum(diag(as.matrix(confusionMatrix(resamp_vbmp$pred, resamp_vbmp$obs)$table))) / sum(colSums(confusionMatrix(resamp_vbmp$pred, resamp_vbmp$obs)$table)) * 100,
         sum(diag(as.matrix(confusionMatrix(resamp_rb$pred, resamp_rb$obs)$table))) / sum(colSums(confusionMatrix(resamp_rb$pred, resamp_rb$obs)$table)) * 100,
         sum(diag(as.matrix(confusionMatrix(resamp_svm$pred, resamp_svm$obs)$table))) / sum(colSums(confusionMatrix(resamp_svm$pred, resamp_svm$obs)$table)) * 100,
         sum(diag(as.matrix(confusionMatrix(resamp_svm_radial$pred, resamp_svm_radial$obs)$table))) / sum(colSums(confusionMatrix(resamp_svm_radial$pred, resamp_svm_radial$obs)$table)) * 100
      ), 2)
      ) %>% 
   tibble::column_to_rownames(var = "model")

accuracies
```

Variational Bayesian Multinomial Probit Regression gave us the best overall accuracy of 89.7% while Gaussian Process with Radial Basis has 87.7% accuracy. Simple SVM with linear kernel gave us the worst overall accuracy of 72.5%.

Both Gaussian Process methods struggle with predicting "Damp Grey Soil" class, but that's what we predicted from scatter plots. While SVM methods showed similar results predicting "Damp Grey Soil" class, but the SVM models had a very hard time predicting "Soil With Vegetation Stubble" while GP methods didnt had a very hard time predicting this class.

# SVM dataset

## Required packages
```{r}
library(SmartEDA)
library(dplyr)
library(ggplot2)
library(caret)
library(R.matlab)
library(kernlab)

# Function for 6 class accuracy from confusion matrix
classAcc <- function(confusionMatrix) {
  class1 <- round(confusionMatrix$table[1, 1] / sum(confusionMatrix$table[, 1]) * 100, 1)
  class2 <- round(confusionMatrix$table[2, 2] / sum(confusionMatrix$table[, 2]) * 100, 1)
  acc <- c(class1, class2 )
  names(acc) <- colnames(confusionMatrix$table)
  return(acc)
}
```

## Reading Data
```{r}
set.seed(123)

annthyroid <- readMat("annthyroid.mat") %>% as.data.frame()
```

## EDA, first look at the dataset
```{r}
ExpData(annthyroid,type=1)
```

We have a dataset of 7200 observations, all 7 variables are of numeric. None of the columns have missing values.

Let's look at the target variable frequencies

```{r}
annthyroid %>% 
   group_by(y) %>% 
   summarise(n = n()) %>% 
   mutate(n_prop = round(n / sum(n) * 100, 2))
```

It's a two-class problem, there's a huge class imbalance of  6666 (92.5%) / 534 (7.5%). In this lab, we are not going to try to address this problem.

Let's look at descriptive statistics of each variable:
```{r}
ExpNumStat(annthyroid,by ="A",round= 2, gp = "y") %>% 
  select(Vname, min, max, mean, median, SD)
```

Nothing seems unordinary.

We should look at the correlation between variables
```{r}
correlation_matrix = cor(annthyroid %>% select(-y))

length(findCorrelation(correlation_matrix, cutoff = 0.99))
length(findCorrelation(correlation_matrix, cutoff = 0.95))
length(findCorrelation(correlation_matrix, cutoff = 0.9))
```

We don't have any variables with higher correlation than 0.9.

We'll look through random scatter plots and see how our target variable is seperated across. We'll save some interesting combinations for later. P.S. we'll use jitter() function to overcome observation overlap.

```{r}
data_plot <- annthyroid %>% 
   select(sample(0:6, 1), sample(0:6, 1), y) %>% 
  mutate(y = as.factor(y))
data_plot_colnames <- colnames(data_plot)
colnames(data_plot) <- c("V_1", "V_2", "y")
data_plot %>% 
   ggplot(aes(x = jitter(V_1), y = jitter(V_2), color = y)) +
   geom_point() +
   xlab(data_plot_colnames[1]) +
   ylab(data_plot_colnames[2])

#combinations <- c("X.3 - X.6", "X.2 - X.3", "X.5 - X.3")
```


```{r}
annthyroid %>% 
   ggplot(aes(x = jitter(X.3), y = jitter(X.6), color = as.factor(y))) +
   geom_point() +
   theme_minimal()
```

Combination of X.3 and X.6 features shows a very small separation between the 2 features. Seems like class 1 lies mostly in the range of X.6 [0 - 0.08] and X.3 [0 - 0.025].

```{r}
annthyroid %>% 
   ggplot(aes(x = jitter(X.2), y = jitter(X.3), color = as.factor(y))) +
   geom_point() +
   theme_minimal()
```

This time, the class separation is much better, when the value of X.2 is greater than 0, there's a high chance the target class will be "1".

```{r}
annthyroid %>% 
   ggplot(aes(x = jitter(X.5), y = jitter(X.3), color = as.factor(y))) +
   geom_point() +
   theme_minimal()
```

A combination of X.3 and X.5 almost shows us no class separation at all.

## Fitting models
### SVM Novelty Detenction - Linear Kernel
```{r}
fold_ids = createFolds(annthyroid$y, k = 5, list = TRUE, returnTrain = FALSE)

nu_list = seq(0.01,0.5,0.01)

collect_CV = array(0, dim = c(length(nu_list),5,5))

for(k in 1:5){
  for( i in 1:length(nu_list)){
    anomaly = ksvm(y ~ .,
                   annthyroid[-fold_ids[[k]], ],
                   kernel = "vanilladot",
                   type = 'one-svc',
                   nu = nu_list[i], kpar = list())
    y_true = annthyroid$y[fold_ids[[k]]]
    y_pred = 1 - 1*(predict(anomaly, annthyroid[fold_ids[[k]], ]))
    confMat = confusionMatrix(table(y_true = y_true, y_pred = y_pred))
    collect_CV[i,1,k] = confMat$overall[1] #overall accuracy
    collect_CV[i,2,k] = confMat$overall[2] #Kappa
    collect_CV[i,3,k] = confMat$overall[5] #NIR rate
    collect_CV[i,4,k] = confMat$byClass[1] #Normal class (0) acc
    collect_CV[i,5,k] = confMat$byClass[2] #Anomaly class (1) acc
    
  }
  print(paste("Done with fold:", k))
}

CV = apply(collect_CV, c(1,2), mean)
```

```{r}
par(mfrow=c(2,2))
plot(nu_list,CV[,1],main="Overall Acc",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,2],main="Kappa value",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,4],main="Normal class acc",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,5],main="Anomaly class acc",xlab="nu",ylab="", type = "l")
```

Accuracy for the anomaly class is really small, no matter what nu value we are choosing.

### SVM Novelty Detenction - Radial Basis Kernel
```{r}
fold_ids = createFolds(annthyroid$y, k = 5, list = TRUE, returnTrain = FALSE)

nu_list = seq(0.01,0.5,0.01)

collect_CV = array(0, dim = c(length(nu_list),5,5))

for(k in 1:5){
  for( i in 1:length(nu_list)){
    for(j in 1:length(kpar_list[[1]])){
    anomaly = ksvm(y ~ .,
                   annthyroid[-fold_ids[[k]], ],
                   kernel = "rbfdot",
                   type = 'one-svc',
                   nu = nu_list[i], kpar = "automatic")
    y_true = annthyroid$y[fold_ids[[k]]]
    y_pred = 1 - 1*(predict(anomaly, annthyroid[fold_ids[[k]], ]))
    confMat = confusionMatrix(table(y_true = y_true, y_pred = y_pred))
    collect_CV[i,1,k] = confMat$overall[1] #overall accuracy
    collect_CV[i,2,k] = confMat$overall[2] #Kappa
    collect_CV[i,3,k] = confMat$overall[5] #NIR rate
    collect_CV[i,4,k] = confMat$byClass[1] #Normal class (0) acc
    collect_CV[i,5,k] = confMat$byClass[2] #Anomaly class (1) acc
    }
    
  }
  print(paste("Done with fold:", k))
}

CV = apply(collect_CV, c(1,2), mean)
```

```{r}
par(mfrow=c(2,2))
plot(nu_list,CV[,1],main="Overall Acc",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,2],main="Kappa value",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,4],main="Normal class acc",xlab="nu",ylab="", type = "l")
plot(nu_list,CV[,5],main="Anomaly class acc",xlab="nu",ylab="", type = "l")
```

The higher the value of nu, the lower accuracy for the anomaly class. Highest accuracy of the anomaly class is reached using nu ~0.05 and the accuracy is ~24%

## Conclusion

Seems like using Radial Basis Kernel gives much better prediction of anomaly class (~24%) while the linear kernel reached only 8% accuracy for the anomaly class